Intro Part of project:
*Twitter Search & Sentiment Analysis Using
API* where Implementation of search and sentiment
analysis using Tweepy & TextBlob module. Further, Functions like API, OAuthHandler and
etc are used for the ease of code and better
analysis.

Explanation of the project:
This project is based on searching and sentiment analysis using API of the twitter platform.. so starting with your twitter account. on twitter , there's a seprate Developer's Portal where a user can register for the private tokens and consumer keys. These keys helps to connect the twitter application from the programming language through an interface which makes the complete sense of how API (application programming interface) works. These keys & tokens can also be regenrated as per the further requirement.
Moving towards the coding part, Pyhton Modules are used in the code. I've used:
Tweepy 
TextBlob

Tweepy is a Python package that gives you a very convenient way to access the Twitter API with Python. This package consist of various methods which has been used in my code. 
*tweepy.OAuthHandler is one of the tweepy's method which is used to check the authority of the user. In other words, we use OAuthHandler to authenticate whether the provided tokens & keys are correct or not. This helps us to set access token in the further steps.
*tweepy.API is a method of the API class in Tweepy module used to fetch a status / tweet. Extraction of live tweets from the user's twitter account is carried out using tweepy.API . We give stored value of the authentication as an input in tweepy.API nd store the whole result in a seprate variable (storage_api_connect variable that u have used in ur code).

On applying the basics of python and the required logic.. I somehow able to develope this code. Taking input from the users regarding the word user want to search on twitter and the no. of tweets that user wants are taken. Further a loop is executed through which we will obtain a whole new live data of the twitter in a scripted form. also we will apply the proper filters such as lang: eng , result_type:'recent' and etc which will make the searching process effective & fast.
*Iterating through the scripted data(JSON response),it helps to make pagination easier and require less code Tweepy has the cursor object tweepy.cursor which i've used in my code. (pagination ka mtlb hua ki jo JSON Response milega.. utna bada response mai jo filters tm apply kiye ho.. tmko direct wahi pe le jaye.. ignoring the rest of the code.. isse searching fast hoga.)

As a result, we get the live tweets data which i've converted into a formal text using .text method.
(yaha tak mai live tweets fetch hogya..)

(Now for the sentiment..)
Using the same process and logic, i've implemented the sentiment analysis. The sentiment functn of textblob consists of two properties.. Polarity and Subjectivity. Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement.
Subjectivity is also a float which lies in the range of [0,1]. In my code, i've used Polarity for the better understanding. 
On framing all the piece of code in a proper manner, i had successfully extracted the twitter live tweets and its sentiments(ploarity).
